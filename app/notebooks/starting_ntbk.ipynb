{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"99db660a-119b-4720-b7db-7e3ebbb80d80","_execution_state":"idle","_uuid":"d390300d4c49a69634911ae2f56d770cac96c232","collapsed":true,"trusted":false},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'seaborn'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[3], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[0;32m     11\u001b[0m sns\u001b[39m.\u001b[39mset_style(\u001b[39m'\u001b[39m\u001b[39mwhitegrid\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mmatplotlib\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minline\u001b[39m\u001b[39m'\u001b[39m)\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"]}],"source":["# Imports\n","\n","# pandas\n","import pandas as pd\n","from pandas import Series,DataFrame\n","\n","# numpy, matplotlib, seaborn\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","sns.set_style('whitegrid')\n","%matplotlib inline\n","\n","# machine learning\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC, LinearSVC\n","from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.naive_bayes import GaussianNB"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"29d2c2ce-cb68-40fc-928e-60af3b8c8958","_uuid":"39f37ec345fdabbc16e109345a1ae5b591bbddc0","collapsed":true,"trusted":false},"outputs":[],"source":["# get titanic & test csv files as a DataFrame\n","titanic_df = pd.read_csv(\"../input/train.csv\")\n","test_df    = pd.read_csv(\"../input/test.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b3d18fa2-bab7-4a8c-89c5-a7f57a7b808b","_uuid":"07b7d5f4d5ac989164ddec4d7ca05cf29677d8db","collapsed":true,"trusted":false},"outputs":[],"source":["# preview the data\n","titanic_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d6d425da-9c2d-4de3-94c7-9d83b236a814","_uuid":"385207a7ae040a51fe47e38bee31f58fefe26ef2","collapsed":true,"trusted":false},"outputs":[],"source":["print(titanic_df.info())\n","print(\"----------------------------\")\n","print(test_df.info())"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8342ac2c-a07c-495f-bec4-30acf480a6ab","_uuid":"835f484bb1c50eb4c193604bb49ddbf4afcb2e6e","collapsed":true,"trusted":false},"outputs":[],"source":["# drop unnecessary columns, these columns won't be useful in analysis and prediction\n","titanic_df = titanic_df.drop(['PassengerId','Name','Ticket'], axis=1)\n","test_df    = test_df.drop(['Name','Ticket'], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6b9f0b1b-cf91-400a-8cc4-180b502f4390","_uuid":"ac3845694f67af7e85367422c759496d37b65244","collapsed":true,"trusted":false},"outputs":[],"source":["# Embarked\n","\n","# only in titanic_df, fill the two missing values with the most occurred value, which is \"S\".\n","titanic_df[\"Embarked\"] = titanic_df[\"Embarked\"].fillna(\"S\")\n","\n","# plot\n","sns.factorplot('Embarked','Survived', data=titanic_df,size=4,aspect=3)\n","\n","fig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(15,5))\n","\n","sns.countplot(x='Embarked', data=titanic_df, ax=axis1)\n","sns.countplot(x='Survived', hue=\"Embarked\", data=titanic_df, order=[1,0], ax=axis2)\n","\n","# group by embarked, and get the mean for survived passengers for each value in Embarked\n","embark_perc = titanic_df[[\"Embarked\", \"Survived\"]].groupby(['Embarked'],as_index=False).mean()\n","sns.barplot(x='Embarked', y='Survived', data=embark_perc,order=['S','C','Q'],ax=axis3)\n","\n","# Either to consider Embarked column in predictions,\n","# and remove \"S\" dummy variable, \n","# and leave \"C\" & \"Q\", since they seem to have a good rate for Survival.\n","\n","# OR, don't create dummy variables for Embarked column, just drop it, \n","# because logically, Embarked doesn't seem to be useful in prediction.\n","\n","embark_dummies_titanic  = pd.get_dummies(titanic_df['Embarked'])\n","embark_dummies_titanic.drop(['S'], axis=1, inplace=True)\n","\n","embark_dummies_test  = pd.get_dummies(test_df['Embarked'])\n","embark_dummies_test.drop(['S'], axis=1, inplace=True)\n","\n","titanic_df = titanic_df.join(embark_dummies_titanic)\n","test_df    = test_df.join(embark_dummies_test)\n","\n","titanic_df.drop(['Embarked'], axis=1,inplace=True)\n","test_df.drop(['Embarked'], axis=1,inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e8d6cb8e-dd37-4856-a9c8-13062bb04c5c","_uuid":"44b111e103736c3f7207b9ad44fcb372319d2db2","collapsed":true,"trusted":false},"outputs":[],"source":["# Fare\n","# only for test_df, since there is a missing \"Fare\" values\n","test_df[\"Fare\"].fillna(test_df[\"Fare\"].mean(), inplace=True)\n","\n","# convert from float to int\n","titanic_df['Fare'] = titanic_df['Fare'].astype(int)\n","test_df['Fare']    = test_df['Fare'].astype(int)\n","\n","# get fare for survived & didn't survive passengers \n","fare_not_survived = titanic_df[\"Fare\"][titanic_df[\"Survived\"] == 0]\n","fare_survived     = titanic_df[\"Fare\"][titanic_df[\"Survived\"] == 1]\n","\n","# get average and std for fare of survived/not survived passengers\n","avgerage_fare = DataFrame([fare_not_survived.mean(), fare_survived.mean()])\n","std_fare      = DataFrame([fare_not_survived.std(), fare_survived.std()])\n","\n","# plot\n","titanic_df['Fare'].plot(kind='hist', figsize=(15,3),bins=100, xlim=(0,50))\n","\n","avgerage_fare.index.names = std_fare.index.names = [\"Survived\"]\n","avgerage_fare.plot(yerr=std_fare,kind='bar',legend=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fdc1708f-5fbd-4f25-a2d3-191a84e66a29","_uuid":"fd58413b3fdfe7e8b4454c52822af1a1cc32d8d7","collapsed":true,"trusted":false},"outputs":[],"source":["# Cabin\n","# It has a lot of NaN values, so it won't cause a remarkable impact on prediction in this simple model\n","titanic_df.drop(\"Cabin\",axis=1,inplace=True)\n","test_df.drop(\"Cabin\",axis=1,inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"088600e9-ca97-4dc0-b776-86f8e840ef85","_uuid":"0225a6a73f121a5244e812501e5fe66b8d8384e9","collapsed":true,"trusted":false},"outputs":[],"source":["# Age \n","# get average, std, and number of NaN values in titanic_df\n","average_age_titanic   = titanic_df[\"Age\"].mean()\n","std_age_titanic       = titanic_df[\"Age\"].std()\n","count_nan_age_titanic = titanic_df[\"Age\"].isnull().sum()\n","\n","# get average, std, and number of NaN values in test_df\n","average_age_test   = test_df[\"Age\"].mean()\n","std_age_test       = test_df[\"Age\"].std()\n","count_nan_age_test = test_df[\"Age\"].isnull().sum()\n","\n","# generate random numbers between (mean - std) & (mean + std)\n","rand_1 = np.random.randint(average_age_titanic - std_age_titanic, average_age_titanic + std_age_titanic, size = count_nan_age_titanic)\n","rand_2 = np.random.randint(average_age_test - std_age_test, average_age_test + std_age_test, size = count_nan_age_test)\n","\n","# drop all null values, and convert to int\n","titanic_df['Age'].dropna().astype(int)\n","# test_df['Age'].dropna().astype(int).hist(bins=70, ax=axis1)\n","\n","# fill NaN values in Age column with random values generated\n","titanic_df[\"Age\"][np.isnan(titanic_df[\"Age\"])] = rand_1\n","test_df[\"Age\"][np.isnan(test_df[\"Age\"])] = rand_2\n","\n","# convert from float to int\n","titanic_df['Age'] = titanic_df['Age'].astype(int)\n","test_df['Age']    = test_df['Age'].astype(int)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cdfb5464-2f89-4dc4-872c-d429dcf4b8f2","_uuid":"14e53e412fe95b255c4c66f07bacdcaa70ad7dd9","collapsed":true,"trusted":false},"outputs":[],"source":["# Sex\n","\n","# As we see, children(age < ~16) on aboard seem to have a high chances for Survival.\n","# So, we can classify passengers as males, females, and child\n","def get_person(passenger):\n","    age,sex = passenger\n","    return 'child' if age < 16 else sex\n","    \n","titanic_df['Person'] = titanic_df[['Age','Sex']].apply(get_person,axis=1)\n","test_df['Person']    = test_df[['Age','Sex']].apply(get_person,axis=1)\n","\n","# No need to use Sex column since we created Person column\n","titanic_df.drop(['Sex'],axis=1,inplace=True)\n","test_df.drop(['Sex'],axis=1,inplace=True)\n","\n","# create dummy variables for Person column, & drop Male as it has the lowest average of survived passengers\n","person_dummies_titanic  = pd.get_dummies(titanic_df['Person'])\n","person_dummies_titanic.columns = ['Child','Female','Male']\n","person_dummies_titanic.drop(['Male'], axis=1, inplace=True)\n","\n","person_dummies_test  = pd.get_dummies(test_df['Person'])\n","person_dummies_test.columns = ['Child','Female','Male']\n","person_dummies_test.drop(['Male'], axis=1, inplace=True)\n","\n","titanic_df = titanic_df.join(person_dummies_titanic)\n","test_df    = test_df.join(person_dummies_test)\n","\n","fig, (axis1,axis2) = plt.subplots(1,2,figsize=(10,5))\n","\n","sns.factorplot('Person',data=titanic_df,kind='count',ax=axis1)\n","#sns.countplot(x='Person', data=titanic_df, ax=axis1)\n","\n","# average of survived for each Person(male, female, or child)\n","person_perc = titanic_df[[\"Person\", \"Survived\"]].groupby(['Person'],as_index=False).mean()\n","sns.barplot(x='Person', y='Survived', data=person_perc, ax=axis2, order=['male','female','child'])\n","\n","titanic_df.drop(['Person'],axis=1,inplace=True)\n","test_df.drop(['Person'],axis=1,inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"20d906f4-4450-4037-b466-d3d31da10479","_uuid":"01285817befba9347f29c4f5912b62f53367233a","collapsed":true,"trusted":false},"outputs":[],"source":["# define training and testing sets\n","\n","X_train = titanic_df.drop(\"Survived\",axis=1)\n","Y_train = titanic_df[\"Survived\"]\n","X_test  = test_df.drop(\"PassengerId\",axis=1).copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8a882725-e7c4-432b-9e4e-659de4600303","_uuid":"46f5bbf67834889b41c707137c3c6f49f57af950","collapsed":true,"trusted":false},"outputs":[],"source":["# Logistic Regression\n","\n","logreg = LogisticRegression()\n","\n","logreg.fit(X_train, Y_train)\n","\n","Y_pred = logreg.predict(X_test)\n","\n","logreg.score(X_train, Y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fb5babf3-8937-4db7-b120-b742e14da44f","_uuid":"74150267911cd39f786ebfd86d553fee902ebc9c","collapsed":true,"trusted":false},"outputs":[],"source":["#Support Vector Machines\n","\n","svc = SVC()\n","\n","svc.fit(X_train, Y_train)\n","\n","Y_pred = svc.predict(X_test)\n","\n","svc.score(X_train, Y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"27476379-e949-4480-a282-8138c8f04580","_uuid":"9bc380c6ccbed68592e8e708c9fb45c14915680a","collapsed":true,"trusted":false},"outputs":[],"source":["# Random Forests\n","\n","random_forest = RandomForestClassifier(n_estimators=100,oob_score=True,max_features=5)\n","\n","random_forest.fit(X_train, Y_train)\n","\n","Y_pred = random_forest.predict(X_test)\n","\n","random_forest.score(X_train, Y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"814d095d-1780-4c0e-bf0e-0caef25a46ee","_uuid":"a62a8ae6baac52c88b34a8c5ec83cb85589f59b5","collapsed":true,"trusted":false},"outputs":[],"source":["random_forest.get_params,random_forest.feature_importances_"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ef553cf8-e958-4029-979c-52ef181c7153","_uuid":"894860dbf49f2cf1e7c63b230d5b228db2ace9c0","collapsed":true,"trusted":false},"outputs":[],"source":["# Gradient Boosts\n","grad_boost = GradientBoostingClassifier(n_estimators=1000)\n","grad_boost.fit(X_train, Y_train)\n","Y_pred = grad_boost.predict(X_test)\n","grad_boost.score(X_train, Y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"46d42b4d-88c0-41db-868e-2f6466e5284a","_uuid":"bcb6ca9da42e0f6647a2e87d4f4ce157de16af13","collapsed":true,"trusted":false},"outputs":[],"source":["# get Correlation Coefficient for each feature using Logistic Regression\n","coeff_df = DataFrame(titanic_df.columns.delete(0))\n","coeff_df.columns = ['Features']\n","coeff_df[\"Coefficient Estimate\"] = pd.Series(logreg.coef_[0])\n","\n","# preview\n","coeff_df"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"12b2eed7-68c5-48ca-9c19-3d4301ea4ca8","_uuid":"3974e5e4ec2681fd99f42e6b5a730d44ab84dbd2","collapsed":true,"trusted":false},"outputs":[],"source":["submission = pd.DataFrame({\n","        \"PassengerId\": test_df[\"PassengerId\"],\n","        \"Survived\": Y_pred\n","    })\n","submission.to_csv('titanic.csv', index=False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":1}
